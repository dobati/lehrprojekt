# Lehrprojekt (V1)


## Repository structure
        annotate.py
		createTables.py
		tables/
			data_input/
				input.tsv
			data_output/
				tokens.tsv
				slavexample.tsv
				category.tsv
			stand_off/
				sourcedesc.csv
				referencedesc.csv
				languages.csv
				categorydesc.csv
			requirements.txt 

## Scripts
		
	annotate.py # takes examples from tables/data_input/input.tsv as input and creates the an annotated and tokenized file in CoNNL-U format (tables/data/output/tokens.tsv)

	createTables.py # takes the token table with example ids generated by annotate.py as input, and creates a table with categories for each example (tables/data_output/categories.tsv) and with other relevant metainformation for each example (slavexample.tsv)
		
Calling the scripts:

	$ pip install -r requirements.txt 

	$ python annotate.py

	$ python createTables.py

## Tables
### Token
The first 9 columns match the standard CoNNL-U format:

1. ID: Word index, integer starting at 1 for each new sentence; may be a range for multiword tokens; may be a decimal number for empty nodes (decimal numbers can be lower than 1 but must be greater than 0).1)
2. FORM: Word form or punctuation symbol.
3. LEMMA: Lemma or stem of word form.
4. UPOS: Universal part-of-speech tag.
5. XPOS: Language-specific part-of-speech tag. (see MULTEXT-East: http://nl.ijs.si/ME/V6/msd/html/index.html)
6. FEATS: List of morphological features from the universal feature inventory or from a defined language-specific extension.
7. HEAD: Head of the current word, which is either a value of ID or zero (0).
8. DEPREL: Universal dependency relation to the HEAD (root iff HEAD = 0) or a defined language-specific subtype of one.
9. MISC: Any other annotation.
10. ENGLISH: English translation of the lemma (created with GoogleTrans Python-Library: https://pypi.org/project/googletrans/)
11. GLOSS: Leipzig Glossing Rules (https://www.eva.mpg.de/lingua/pdf/Glossing-Rules.pdf)
12. GLOSSKORR: Corrected annotations from the column GLOSS
13. OMIT_ANNOTATIONS: The value "_omit_annotations_" in this column stands for those tokens for which the annotations must not be shown on the Web-Interface
14. TOKENID: Language specific string (LANGCODE + VERSION + str((range of 1 million))
15. EXAMPLEID: Language specific string (LANGCODE + VERSION + str(range of 1000))
16. _CAT: Category
17. _EDITOR: Editor of the Example

The columns 16. and 17. are only there for our information and should be removed from the final table

### Category
1. CAT: Category for the example
2. EXAMPLEID: Language specific string (LANGCODE + VERSION + str(range of 1000))

### SlavExample
1. SOURCE: The corpus or Website in which the example has been found
2. REFERENCE: The written source in which the example has been found in the Format: Author (Year)
3. REFERENCE_PAGE: The page for the quote in REFERENCE
4. GROUPID: ID for all examples that  belong together in a group and should appear together on the Web-Interface
5. _EDITOR: Person responsable for this example (should not appear on the Web-Interface)
6. COMMENT: Comment that should appear for users to see
7. VERSION: The version in which the example has been introduced
8. _COMMENT_INTERN: Comment that is there for authors information (should not appear on the Web-Interface)
9. EXAMPLEID: Language specific string (LANGCODE + VERSION  + str(range of 1000))


## Stand-Off csv

### sourcedesc
1. SOURCE: Source (short)
2. DESC: Source (long)

### referencedesc
1. REFERENCE: Reference (short)
2. DESC: Reference (long)

### languages
1. LANGUAGE: Language
2. LANGCODE: (Language code like ru, bcms, etc.)

### categorydesc
1. CAT: Category (short)
2. DESC: Category
3. INFO: Information about this category
				

### Requirements

Python 3.7

Libraries

	certifi==2021.10.8

	chardet==3.0.4

	charset-normalizer==2.0.12

	classla==1.1.0

	emoji==1.6.3

	googletrans==3.1.0a0

	h11==0.9.0

	h2==3.2.0

	hpack==3.0.0

	hstspreload==2021.12.1

	httpcore==0.9.1

	httpx==0.13.3

	hyperframe==5.2.0

	idna==2.10

	lxml==4.7.1

	numpy==1.22.2

	obeliks==1.1.4

	protobuf==3.19.4

	regex==2022.1.18

	reldi-tokeniser==1.0.1

	requests==2.27.1

	rfc3986==1.5.0

	six==1.16.0

	sniffio==1.2.0

	stanza==1.2.3

	torch==1.10.2

	tqdm==4.62.3

	typing_extensions==4.1.1

	urllib3==1.26.8
