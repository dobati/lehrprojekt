# Lehrprojekt (V1)


## Repository structure
    requirements.txt 
    annotate.py
    createTables.py
    tables/
		data_input/
			input.tsv
		data_output/
			tokens.tsv
			slavexample.tsv
			category.tsv
		stand_off/
			sourcedesc.tsv
			referencedesc.tsv
			languages.tsv
			categorydesc.tsv
		

## Scripts
		
	annotate.py # takes examples from tables/data_input/input.tsv as input and creates the an annotated and tokenized file in CoNNL-U format (tables/data/output/tokens.tsv)

	createTables.py # takes the token table with example ids generated by annotate.py as input, and creates a table with categories for each example (tables/data_output/categories.tsv) and with other relevant metainformation for each example (slavexample.tsv)
		
Calling the scripts:

	$ pip install -r requirements.txt 

	$ python annotate.py

	$ python createTables.py

## Tables
### tokens.tsv
The first 9 columns match the standard CoNNL-U format:

1. ID: Word index, integer starting at 1 for each new sentence; may be a range for multiword tokens; may be a decimal number for empty nodes (decimal numbers can be lower than 1 but must be greater than 0).1)
2. FORM: Word form or punctuation symbol.
3. LEMMA: Lemma or stem of word form.
4. UPOS: Universal part-of-speech tag.
5. XPOS: Language-specific part-of-speech tag. (see MULTEXT-East: http://nl.ijs.si/ME/V6/msd/html/index.html)
6. FEATS: List of morphological features from the universal feature inventory or from a defined language-specific extension.
7. HEAD: Head of the current word, which is either a value of ID or zero (0).
8. DEPREL: Universal dependency relation to the HEAD (root iff HEAD = 0) or a defined language-specific subtype of one.
9. MISC: Any other annotation.
10. ENGLISH: English translation of the lemma (created with GoogleTrans Python-Library for Serbian and DeepL API for other languages)
11. GLOSS: Leipzig Glossing Rules (https://www.eva.mpg.de/lingua/pdf/Glossing-Rules.pdf)
12. GLOSSKORR: Corrected annotations from the column GLOSS
13. OMIT_ANNOTATIONS: The value "_omit_annotations_" in this column stands for those tokens for which the annotations must not be shown on the Web-Interface
14. TOKENID: Language specific string (LANGCODE + VERSION + str((range of 1 million))
15. EXAMPLEID: Language specific string (LANGCODE + VERSION + str(range of 1000))
16. _CAT: Category
17. _EDITOR: Editor of the Example

The columns 16. and 17. are only there for our information and should be removed from the final table

### category.tsv
1. CAT: Category for the example
2. EXAMPLEID: Language specific string (LANGCODE + VERSION + str(range of 1000))

### slavexample.tsv
1. SOURCE: The corpus or Website in which the example has been found
2. REFERENCE: The written source in which the example has been found in the Format: Author (Year)
3. REFERENCE_PAGE: The page for the quote in REFERENCE
4. GROUPID: ID for all examples that  belong together in a group and should appear together on the Web-Interface
5. _EDITOR: Person responsable for this example (should not appear on the Web-Interface)
6. COMMENT: Comment that should appear for users to see
7. VERSION: The version in which the example has been introduced
8. _COMMENT_INTERN: Comment that is there for authors information (should not appear on the Web-Interface)
9. EXAMPLEID: Language specific string (LANGCODE + VERSION  + str(range of 1000))


## Stand-Off tsv

### sourcedesc.tsv
1. SOURCE: Source (short)
2. DESC: Source (long)

### referencedesc.tsv
1. REFERENCE: Reference (short)
2. DESC: Reference (long)

### languages.tsv
1. LANGUAGE: Language
2. LANGCODE: (Language code like ru, bcms, etc.)

### categorydesc.tsv
1. CAT: Category (short)
2. DESC: Category
3. INFO: Information about this category
				

### Requirements

Python 3.10

Libraries (see requirements.txt)